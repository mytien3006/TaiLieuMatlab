{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Brain Tumor Detection Mask R-CNN.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mytien3006/TaiLieuMatlab/blob/master/Brain_Tumor_Detection_Mask_R_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlFvZpQdFyjH"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvnDXM1fH4xN"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "!pip install q keras==2.1.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sX6vOG9AF4Qm"
      },
      "source": [
        "%cd /content/drive/MyDrive/BraTS-20210512T234613Z-002"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hxA1mRhFpw9"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "!git clone https://github.com/matterport/Mask_RCNN.git # load Mask R-CNN code implementation\n",
        "!git clone https://github.com/ruslan-kl/brain-tumor.git # load new data set and annotations \n",
        "!pip install pycocotools\n",
        "\n",
        "!rm -rf brain-tumor/.git/\n",
        "!rm -rf Mask_RCNN/.git/\n",
        "\n",
        "clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEV91vKOGEDW"
      },
      "source": [
        "import os \n",
        "import sys\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "import numpy as np\n",
        "import json\n",
        "import skimage.draw\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "# Root directory of the project\n",
        "ROOT_DIR = os.path.abspath('Mask_RCNN/')\n",
        "# Import Mask RCNN\n",
        "sys.path.append(ROOT_DIR) \n",
        "from mrcnn.config import Config\n",
        "from mrcnn import utils\n",
        "from mrcnn.model import log\n",
        "import mrcnn.model as modellib\n",
        "from mrcnn import visualize\n",
        "# Import COCO config\n",
        "sys.path.append(os.path.join(ROOT_DIR, 'samples/coco/'))\n",
        "import coco\n",
        "\n",
        "plt.rcParams['figure.facecolor'] = 'white'\n",
        "\n",
        "clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDBEA4cAl0ig"
      },
      "source": [
        "def get_ax(rows=1, cols=1, size=7):\n",
        "    \"\"\"Return a Matplotlib Axes array to be used in\n",
        "    all visualizations in the notebook. Provide a\n",
        "    central point to control graph sizes.\n",
        "    \n",
        "    Change the default size attribute to control the size\n",
        "    of rendered images\n",
        "    \"\"\"\n",
        "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
        "    return ax"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcjMAq2iGKfW"
      },
      "source": [
        "MODEL_DIR = os.path.join(ROOT_DIR, 'logs') # directory to save logs and trained model\n",
        "# ANNOTATIONS_DIR = 'brain-tumor/data/new/annotations/' # directory with annotations for train/val sets\n",
        "DATASET_DIR = 'brain-tumor/data_cleaned/' # directory with image data\n",
        "DEFAULT_LOGS_DIR = 'logs' \n",
        "\n",
        "# Local path to trained weights file\n",
        "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
        "# Download COCO trained weights from Releases if needed\n",
        "if not os.path.exists(COCO_MODEL_PATH):\n",
        "    utils.download_trained_weights(COCO_MODEL_PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2ogdvWZGTcX"
      },
      "source": [
        "class TumorConfig(Config):\n",
        "    \"\"\"Configuration for training on the brain tumor dataset.\n",
        "    \"\"\"\n",
        "    # Give the configuration a recognizable name\n",
        "    NAME = 'tumor_detector'\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "    NUM_CLASSES = 1 + 1  # background + tumor\n",
        "    DETECTION_MIN_CONFIDENCE = 0.85    \n",
        "    STEPS_PER_EPOCH = 100\n",
        "    LEARNING_RATE = 0.001\n",
        "    \n",
        "config = TumorConfig()\n",
        "config.display()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9ABdunzLfxx"
      },
      "source": [
        "class BrainScanDataset(utils.Dataset):\n",
        "\n",
        "    def load_brain_scan(self, dataset_dir, subset):\n",
        "        \"\"\"Load a subset of the FarmCow dataset.\n",
        "        dataset_dir: Root directory of the dataset.\n",
        "        subset: Subset to load: train or val\n",
        "        \"\"\"\n",
        "        # Add classes. We have only one class to add.\n",
        "        self.add_class(\"tumor\", 1, \"tumor\")\n",
        "\n",
        "        # Train or validation dataset?\n",
        "        assert subset in [\"train\", \"val\", 'test']\n",
        "        dataset_dir = os.path.join(dataset_dir, subset)\n",
        "\n",
        "        annotations = json.load(open(os.path.join(DATASET_DIR, subset, 'annotations_'+subset+'.json')))\n",
        "        annotations = list(annotations.values())  # don't need the dict keys\n",
        "\n",
        "        # The VIA tool saves images in the JSON even if they don't have any\n",
        "        # annotations. Skip unannotated images.\n",
        "        annotations = [a for a in annotations if a['regions']]\n",
        "\n",
        "        # Add images\n",
        "        for a in annotations:\n",
        "            # Get the x, y coordinaets of points of the polygons that make up\n",
        "            # the outline of each object instance. These are stores in the\n",
        "            # shape_attributes (see json format above)\n",
        "            # The if condition is needed to support VIA versions 1.x and 2.x.\n",
        "            if type(a['regions']) is dict:\n",
        "                polygons = [r['shape_attributes'] for r in a['regions'].values()]\n",
        "            else:\n",
        "                polygons = [r['shape_attributes'] for r in a['regions']]\n",
        "\n",
        "            # load_mask() needs the image size to convert polygons to masks.\n",
        "            # Unfortunately, VIA doesn't include it in JSON, so we must read\n",
        "            # the image. This is only managable since the dataset is tiny.\n",
        "            image_path = os.path.join(dataset_dir, a['filename'])\n",
        "            image = skimage.io.imread(image_path)\n",
        "            height, width = image.shape[:2]\n",
        "\n",
        "            self.add_image(\n",
        "                \"tumor\",\n",
        "                image_id=a['filename'],  # use file name as a unique image id\n",
        "                path=image_path,\n",
        "                width=width, \n",
        "                height=height,\n",
        "                polygons=polygons\n",
        "            )\n",
        "\n",
        "    def load_mask(self, image_id):\n",
        "        \"\"\"Generate instance masks for an image.\n",
        "       Returns:\n",
        "        masks: A bool array of shape [height, width, instance count] with\n",
        "            one mask per instance.\n",
        "        class_ids: a 1D array of class IDs of the instance masks.\n",
        "        \"\"\"\n",
        "        # If not a farm_cow dataset image, delegate to parent class.\n",
        "        image_info = self.image_info[image_id]\n",
        "        if image_info[\"source\"] != \"tumor\":\n",
        "            return super(self.__class__, self).load_mask(image_id)\n",
        "\n",
        "        # Convert polygons to a bitmap mask of shape\n",
        "        # [height, width, instance_count]\n",
        "        info = self.image_info[image_id]\n",
        "        mask = np.zeros([info[\"height\"], info[\"width\"], len(info[\"polygons\"])],\n",
        "                        dtype=np.uint8)\n",
        "        for i, p in enumerate(info[\"polygons\"]):\n",
        "            # Get indexes of pixels inside the polygon and set them to 1\n",
        "            rr, cc = skimage.draw.polygon(p['all_points_y'], p['all_points_x'])\n",
        "            mask[rr, cc, i] = 1\n",
        "\n",
        "        # Return mask, and array of class IDs of each instance. Since we have\n",
        "        # one class ID only, we return an array of 1s\n",
        "        return mask.astype(np.bool), np.ones([mask.shape[-1]], dtype=np.int32)\n",
        "\n",
        "    def image_reference(self, image_id):\n",
        "        \"\"\"Return the path of the image.\"\"\"\n",
        "        info = self.image_info[image_id]\n",
        "        if info[\"source\"] == \"tumor\":\n",
        "            return info[\"path\"]\n",
        "        else:\n",
        "            super(self.__class__, self).image_reference(image_id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKycFQtOIXHF"
      },
      "source": [
        "# Training dataset.\n",
        "dataset_train = BrainScanDataset()\n",
        "dataset_train.load_brain_scan(DATASET_DIR, 'train')\n",
        "dataset_train.prepare()\n",
        "\n",
        "# Validation dataset\n",
        "dataset_val = BrainScanDataset()\n",
        "dataset_val.load_brain_scan(DATASET_DIR, 'val')\n",
        "dataset_val.prepare()\n",
        "\n",
        "dataset_test = BrainScanDataset()\n",
        "dataset_test.load_brain_scan(DATASET_DIR, 'test')\n",
        "dataset_test.prepare()\n",
        "\n",
        "# Since we're using a very small dataset, and starting from\n",
        "# COCO trained weights, we don't need to train too long. Also,\n",
        "# no need to train all layers, just the heads should do it.\n",
        "print(\"Training network heads\")\n",
        "model.train(\n",
        "    dataset_train, dataset_val,\n",
        "    learning_rate=config.LEARNING_RATE,\n",
        "    epochs=15,\n",
        "    layers='heads'\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Z_47sWtVKOx"
      },
      "source": [
        "# Recreate the model in inference mode\n",
        "model = modellib.MaskRCNN(\n",
        "    mode=\"inference\", \n",
        "    config=config,\n",
        "    model_dir=DEFAULT_LOGS_DIR\n",
        ")\n",
        "\n",
        "# Get path to saved weights\n",
        "# Either set a specific path or find last trained weights\n",
        "# model_path = os.path.join(ROOT_DIR, \".h5 file name here\")\n",
        "model_path = model.find_last()\n",
        "\n",
        "# Load trained weights\n",
        "print(\"Loading weights from \", model_path)\n",
        "model.load_weights(model_path, by_name=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTp7BFBDVfOt"
      },
      "source": [
        "import keras\n",
        "# Save the Keras Model\n",
        "keras.models.save_model(model.keras_model,\"mask_rcnn_coco.hdf5\")\n",
        "\n",
        "# Save weights\n",
        "model.keras_model.save_weights(\"mask_rcnn_coco.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRIu6RByLyF6"
      },
      "source": [
        "def predict_and_plot_differences(dataset, img_id):\n",
        "    original_image, image_meta, gt_class_id, gt_box, gt_mask =\\\n",
        "        modellib.load_image_gt(dataset, config, \n",
        "                               img_id, use_mini_mask=False)\n",
        "\n",
        "    results = model.detect([original_image], verbose=0)\n",
        "    r = results[0]\n",
        "\n",
        "    visualize.display_differences(\n",
        "        original_image,\n",
        "        gt_box, gt_class_id, gt_mask,\n",
        "        r['rois'], r['class_ids'], r['scores'], r['masks'],\n",
        "        class_names = ['tumor'], title=\"\", ax=get_ax(),\n",
        "        show_mask=True, show_box=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QE36Ypw7WZQI"
      },
      "source": [
        "def display_image(dataset, ind):\n",
        "    plt.figure(figsize=(5,5))\n",
        "    plt.imshow(dataset.load_image(ind))\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.title('Original Image')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-_dD1JlW_MR"
      },
      "source": [
        "ind = 0\n",
        "display_image(dataset_val, ind)\n",
        "predict_and_plot_differences(dataset_val, ind)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6f24s43uL3YC"
      },
      "source": [
        "ind = 10\n",
        "display_image(dataset_val, ind)\n",
        "predict_and_plot_differences(dataset_val, ind)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nkl5KdpzL5VL"
      },
      "source": [
        "ind = 4\n",
        "display_image(dataset_val, ind)\n",
        "predict_and_plot_differences(dataset_val, ind)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDnvhHZML7UL"
      },
      "source": [
        "ind = 0\n",
        "display_image(dataset_test, ind)\n",
        "predict_and_plot_differences(dataset_test, ind)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MI6agsqMmvHH"
      },
      "source": [
        "ind = 1\n",
        "display_image(dataset_test, ind)\n",
        "predict_and_plot_differences(dataset_test, ind)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}